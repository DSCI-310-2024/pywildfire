{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "Here, we will demonstrate how to utilize the modules in `pywildfire` to access data and use it to help create a predictive model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywildfire\n",
    "\n",
    "print(pywildfire.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywildfire.pyprep import *\n",
    "from pywildfire.pyfeats import relevant_features\n",
    "from pywildfire.pywildfire import calculate_rmse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import requests\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access a zipped data source through its URL\n",
    "\n",
    "We will first specify the location in which we would like the store the file(s) locally, and then plug both the output path and the URL into `download_extract_data`.\n",
    "\n",
    "The following example zip file has been fabricated in order to illustrate the utility of the functions in this package. It contains three files: 01_example_data.csv, 02_example_data.txt, and 03_example_data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://example.com/data.zip\"\n",
    "output_path = './data'\n",
    "download_extract_data(url, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what your working directory will look like after calling the function:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "your_working_directory  \n",
    "├── data  \n",
    "│    └── 01_example_data.csv  \n",
    "│    └── 02_example_data.txt  \n",
    "│    └── 03_example_data.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data in your environment\n",
    "Next, we can download the data as a pandas DataFrame in our Python IDE of choice using `get_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '01_example_data.csv'\n",
    "data = get_csv(output_path, csv_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "   A   B  C   D       E\n",
    "0  1  10  1  50   small\n",
    "1  3   6  2  30  medium\n",
    "2  5   8  3  40   large\n",
    "3  7   2  4  10   small\n",
    "4  9   4  5  20  medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale numeric variables\n",
    "\n",
    "Now, we will scale the columns in our dataframe that are numeric using `scale_numeric_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scale_numeric_df(sample_data)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "          A         B         C         D\n",
    "0 -1.414214  1.414214 -1.414214  1.414214\n",
    "1 -0.707107  0.000000 -0.707107  0.000000\n",
    "2  0.000000  0.707107  0.000000  0.707107\n",
    "3  0.707107 -1.414214  0.707107 -1.414214\n",
    "4  1.414214 -0.707107  1.414214 -0.707107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Relevant Features\n",
    "\n",
    "You can create a correlation matrix using the `corr()` method from pandas, which can then be used as a parameter alongside your defined target variable in the `relevant_features` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = scaled_data.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "     A    B    C    D\n",
    "A  1.0 -0.8  1.0 -0.8\n",
    "B -0.8  1.0 -0.8  1.0\n",
    "C  1.0 -0.8  1.0 -0.8\n",
    "D -0.8  1.0 -0.8  1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'A'\n",
    "\n",
    "feats = relevant_features(corr_matrix, target_variable)\n",
    "feats"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "C    1.0\n",
    "B   -0.8\n",
    "D   -0.8\n",
    "Name: A, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "After separating your target and feature variables, splitting your data into test and train sets, and fitting a model appropriate for your data, and using it to to predict your target variable, `calculate_rmse` can be used to generate the root mean squared error (RMSE) between the observed and predicted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = pd.Series([4, 8, 5, 3, 7])\n",
    "predicted = pd.Series([16, 4, 7, 9, 3])\n",
    "\n",
    "result = calculate_rmse(observed, predicted)\n",
    "result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6.572670690061994"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
